{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8646a28c-dde6-4f70-89b2-e49c0f237235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import  GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a6b7da-1382-452b-b576-dbda47009d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29fcc1b-96ea-40a2-a911-a6bb25335731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    TRAIN_PATH = '../inputs/train.csv'\n",
    "    TEST_PATH = '../inputs/test.csv'\n",
    "    TRAIN_LABELS = '../inputs/train_labels.csv'\n",
    "    SAMPLE_SUBMISSION = '../inputs/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f895cae1-0e17-4388-b22d-7f8256d985c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2l(x):\n",
    "    if x <= 3:\n",
    "        return '0-4'\n",
    "    if x <= 13:\n",
    "        return '5-12'\n",
    "    return '13-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4167f52-f7d7-43ae-9e66-7808cf4db982",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_features =  ['checkpoint_click','cutscene_click', 'person_click', 'navigate_click',\n",
    "                   'observation_click', 'notification_click', 'object_click',\n",
    "                   'object_hover', 'map_hover', 'map_click', 'notebook_click']\n",
    "room_features = ['historicalsociety',\n",
    "          'kohlcenter',\n",
    "          'capitol_0',\n",
    "          'humanecology',\n",
    "          'drycleaner',\n",
    "          'library',\n",
    "          'capitol_1',\n",
    "          'wildlife',\n",
    "          'flaghouse','capitol_2']\n",
    "fqid_lists = ['worker', 'archivist', 'gramps', 'wells', 'toentry', 'confrontation', 'crane_ranger', 'groupconvo', 'flag_girl', 'tomap', 'tostacks', 'tobasement', 'archivist_glasses', 'boss', 'journals', 'seescratches', 'groupconvo_flag', 'cs', 'teddy', 'expert', 'businesscards', 'ch3start', 'tunic.historicalsociety', 'tofrontdesk', 'savedteddy', 'plaque', 'glasses', 'tunic.drycleaner', 'reader_flag', 'tunic.library', 'tracks', 'tunic.capitol_2', 'trigger_scarf', 'reader', 'directory', 'tunic.capitol_1', 'journals.pic_0.next', 'unlockdoor', 'tunic', 'what_happened', 'tunic.kohlcenter', 'tunic.humanecology', 'colorbook', 'logbook', 'businesscards.card_0.next', 'journals.hub.topics', 'logbook.page.bingo', 'journals.pic_1.next', 'journals_flag', 'reader.paper0.next', 'tracks.hub.deer', 'reader_flag.paper0.next', 'trigger_coffee', 'wellsbadge', 'journals.pic_2.next', 'tomicrofiche', 'journals_flag.pic_0.bingo', 'plaque.face.date', 'notebook', 'tocloset_dirty', 'businesscards.card_bingo.bingo', 'businesscards.card_1.next', 'tunic.wildlife', 'tunic.hub.slip', 'tocage', 'journals.pic_2.bingo', 'tocollectionflag', 'tocollection', 'chap4_finale_c', 'chap2_finale_c', 'lockeddoor', 'journals_flag.hub.topics', 'tunic.capitol_0', 'reader_flag.paper2.bingo', 'photo', 'tunic.flaghouse', 'reader.paper1.next', 'directory.closeup.archivist', 'intro', 'businesscards.card_bingo.next', 'reader.paper2.bingo', 'retirement_letter', 'remove_cup', 'journals_flag.pic_0.next', 'magnify', 'coffee', 'key', 'togrampa', 'reader_flag.paper1.next', 'janitor', 'tohallway', 'chap1_finale', 'report', 'outtolunch', 'journals_flag.hub.topics_old', 'journals_flag.pic_1.next', 'reader.paper2.next', 'chap1_finale_c', 'reader_flag.paper2.next', 'door_block_talk', 'journals_flag.pic_1.bingo', 'journals_flag.pic_2.next', 'journals_flag.pic_2.bingo', 'block_magnify', 'reader.paper0.prev', 'block', 'reader_flag.paper0.prev', 'block_0', 'door_block_clean', 'reader.paper2.prev', 'reader.paper1.prev', 'doorblock', 'tocloset', 'reader_flag.paper2.prev', 'reader_flag.paper1.prev', 'block_tomap2', 'journals_flag.pic_0_old.next', 'journals_flag.pic_1_old.next', 'block_tocollection', 'block_nelson', 'journals_flag.pic_2_old.next', 'block_tomap1', 'block_badge', 'need_glasses', 'block_badge_2', 'fox', 'block_1']\n",
    "\n",
    "name_feature = ['basic', 'undefined', 'close', 'open', 'prev', 'next']\n",
    "event_name_feature = ['cutscene_click', 'person_click', 'navigate_click',\n",
    "       'observation_click', 'notification_click', 'object_click',\n",
    "       'object_hover', 'map_hover', 'map_click', 'checkpoint',\n",
    "       'notebook_click']\n",
    "text_lists = ['tunic.historicalsociety.cage.confrontation', 'tunic.wildlife.center.crane_ranger.crane', 'tunic.historicalsociety.frontdesk.archivist.newspaper', 'tunic.historicalsociety.entry.groupconvo', 'tunic.wildlife.center.wells.nodeer', 'tunic.historicalsociety.frontdesk.archivist.have_glass', 'tunic.drycleaner.frontdesk.worker.hub', 'tunic.historicalsociety.closet_dirty.gramps.news', 'tunic.humanecology.frontdesk.worker.intro', 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation', 'tunic.historicalsociety.basement.seescratches', 'tunic.historicalsociety.collection.cs', 'tunic.flaghouse.entry.flag_girl.hello', 'tunic.historicalsociety.collection.gramps.found', 'tunic.historicalsociety.basement.ch3start', 'tunic.historicalsociety.entry.groupconvo_flag', 'tunic.library.frontdesk.worker.hello', 'tunic.library.frontdesk.worker.wells', 'tunic.historicalsociety.collection_flag.gramps.flag', 'tunic.historicalsociety.basement.savedteddy', 'tunic.library.frontdesk.worker.nelson', 'tunic.wildlife.center.expert.removed_cup', 'tunic.library.frontdesk.worker.flag', 'tunic.historicalsociety.frontdesk.archivist.hello', 'tunic.historicalsociety.closet.gramps.intro_0_cs_0', 'tunic.historicalsociety.entry.boss.flag', 'tunic.flaghouse.entry.flag_girl.symbol', 'tunic.historicalsociety.closet_dirty.trigger_scarf', 'tunic.drycleaner.frontdesk.worker.done', 'tunic.historicalsociety.closet_dirty.what_happened', 'tunic.wildlife.center.wells.animals', 'tunic.historicalsociety.closet.teddy.intro_0_cs_0', 'tunic.historicalsociety.cage.glasses.afterteddy', 'tunic.historicalsociety.cage.teddy.trapped', 'tunic.historicalsociety.cage.unlockdoor', 'tunic.historicalsociety.stacks.journals.pic_2.bingo', 'tunic.historicalsociety.entry.wells.flag', 'tunic.humanecology.frontdesk.worker.badger', 'tunic.historicalsociety.stacks.journals_flag.pic_0.bingo', 'tunic.historicalsociety.closet.intro', 'tunic.historicalsociety.closet.retirement_letter.hub', 'tunic.historicalsociety.entry.directory.closeup.archivist', 'tunic.historicalsociety.collection.tunic.slip', 'tunic.kohlcenter.halloffame.plaque.face.date', 'tunic.historicalsociety.closet_dirty.trigger_coffee', 'tunic.drycleaner.frontdesk.logbook.page.bingo', 'tunic.library.microfiche.reader.paper2.bingo', 'tunic.kohlcenter.halloffame.togrampa', 'tunic.capitol_2.hall.boss.haveyougotit', 'tunic.wildlife.center.wells.nodeer_recap', 'tunic.historicalsociety.cage.glasses.beforeteddy', 'tunic.historicalsociety.closet_dirty.gramps.helpclean', 'tunic.wildlife.center.expert.recap', 'tunic.historicalsociety.frontdesk.archivist.have_glass_recap', 'tunic.historicalsociety.stacks.journals_flag.pic_1.bingo', 'tunic.historicalsociety.cage.lockeddoor', 'tunic.historicalsociety.stacks.journals_flag.pic_2.bingo', 'tunic.historicalsociety.collection.gramps.lost', 'tunic.historicalsociety.closet.notebook', 'tunic.historicalsociety.frontdesk.magnify', 'tunic.humanecology.frontdesk.businesscards.card_bingo.bingo', 'tunic.wildlife.center.remove_cup', 'tunic.library.frontdesk.wellsbadge.hub', 'tunic.wildlife.center.tracks.hub.deer', 'tunic.historicalsociety.frontdesk.key', 'tunic.library.microfiche.reader_flag.paper2.bingo', 'tunic.flaghouse.entry.colorbook', 'tunic.wildlife.center.coffee', 'tunic.capitol_1.hall.boss.haveyougotit', 'tunic.historicalsociety.basement.janitor', 'tunic.historicalsociety.collection_flag.gramps.recap', 'tunic.wildlife.center.wells.animals2', 'tunic.flaghouse.entry.flag_girl.symbol_recap', 'tunic.historicalsociety.closet_dirty.photo', 'tunic.historicalsociety.stacks.outtolunch', 'tunic.library.frontdesk.worker.wells_recap', 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation_recap', 'tunic.capitol_0.hall.boss.talktogramps', 'tunic.historicalsociety.closet.photo', 'tunic.historicalsociety.collection.tunic', 'tunic.historicalsociety.closet.teddy.intro_0_cs_5', 'tunic.historicalsociety.closet_dirty.gramps.archivist', 'tunic.historicalsociety.closet_dirty.door_block_talk', 'tunic.historicalsociety.entry.boss.flag_recap', 'tunic.historicalsociety.frontdesk.archivist.need_glass_0', 'tunic.historicalsociety.entry.wells.talktogramps', 'tunic.historicalsociety.frontdesk.block_magnify', 'tunic.historicalsociety.frontdesk.archivist.foundtheodora', 'tunic.historicalsociety.closet_dirty.gramps.nothing', 'tunic.historicalsociety.closet_dirty.door_block_clean', 'tunic.capitol_1.hall.boss.writeitup', 'tunic.library.frontdesk.worker.nelson_recap', 'tunic.library.frontdesk.worker.hello_short', 'tunic.historicalsociety.stacks.block', 'tunic.historicalsociety.frontdesk.archivist.need_glass_1', 'tunic.historicalsociety.entry.boss.talktogramps', 'tunic.historicalsociety.frontdesk.archivist.newspaper_recap', 'tunic.historicalsociety.entry.wells.flag_recap', 'tunic.drycleaner.frontdesk.worker.done2', 'tunic.library.frontdesk.worker.flag_recap', 'tunic.humanecology.frontdesk.block_0', 'tunic.library.frontdesk.worker.preflag', 'tunic.historicalsociety.basement.gramps.seeyalater', 'tunic.flaghouse.entry.flag_girl.hello_recap', 'tunic.historicalsociety.closet.doorblock', 'tunic.drycleaner.frontdesk.worker.takealook', 'tunic.historicalsociety.basement.gramps.whatdo', 'tunic.library.frontdesk.worker.droppedbadge', 'tunic.historicalsociety.entry.block_tomap2', 'tunic.library.frontdesk.block_nelson', 'tunic.library.microfiche.block_0', 'tunic.historicalsociety.entry.block_tocollection', 'tunic.historicalsociety.entry.block_tomap1', 'tunic.historicalsociety.collection.gramps.look_0', 'tunic.library.frontdesk.block_badge', 'tunic.historicalsociety.cage.need_glasses', 'tunic.library.frontdesk.block_badge_2', 'tunic.kohlcenter.halloffame.block_0', 'tunic.capitol_0.hall.chap1_finale_c', 'tunic.capitol_1.hall.chap2_finale_c', 'tunic.capitol_2.hall.chap4_finale_c', 'tunic.wildlife.center.fox.concern', 'tunic.drycleaner.frontdesk.block_0', 'tunic.historicalsociety.entry.gramps.hub', 'tunic.humanecology.frontdesk.block_1', 'tunic.drycleaner.frontdesk.block_1']\n",
    "room_lists = ['tunic.historicalsociety.entry', 'tunic.wildlife.center', 'tunic.historicalsociety.cage', 'tunic.library.frontdesk', 'tunic.historicalsociety.frontdesk', 'tunic.historicalsociety.stacks', 'tunic.historicalsociety.closet_dirty', 'tunic.humanecology.frontdesk', 'tunic.historicalsociety.basement', 'tunic.kohlcenter.halloffame', 'tunic.library.microfiche', 'tunic.drycleaner.frontdesk', 'tunic.historicalsociety.collection', 'tunic.historicalsociety.closet', 'tunic.flaghouse.entry', 'tunic.historicalsociety.collection_flag', 'tunic.capitol_1.hall', 'tunic.capitol_0.hall', 'tunic.capitol_2.hall']\n",
    "\n",
    "LEVELS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
    "level_groups = [\"0-4\", \"5-12\", \"13-22\"]\n",
    "\n",
    "def groupby_apply(g):\n",
    "    res = {}\n",
    "    elasped_time = g['elapsed_time'].values/1000\n",
    "    level = g['level'].values\n",
    "    res['duration'] = elasped_time.max() - elasped_time.min()\n",
    "    for i in range(0,23):\n",
    "        t = elasped_time[level==i]\n",
    "        if len(t) > 0 :\n",
    "            res[f'duration_level_{i}'] = t.max()-t.min()\n",
    "        else:\n",
    "            res[f'duration_level_{i}'] = 0\n",
    "    res['text_fqid_null'] = pd.isnull(g['text_fqid']).sum()\n",
    "    event_name_dict = Counter(g['event_name'].values)\n",
    "    event_sequence = g['event_name'].values\n",
    "    room_event_dict = Counter(g['room_event'].values)\n",
    "    room_sequence = g['main_room'].values\n",
    "    for col in event_features:\n",
    "        res[f'{col}_sum'] = event_name_dict.get(col, 0)\n",
    "        for col2 in room_features:\n",
    "            res[f'{col}_{col2}_sum'] = room_event_dict.get(f'{col}_{col2}',0)\n",
    "    room_dict = Counter(g['main_room'].values)\n",
    "    for col in room_features:\n",
    "        res[f'{col}_sum'] = room_dict.get(col, 0)\n",
    "\n",
    "    elapsed_time_diff_all = g['elapsed_time_diff'].values\n",
    "    res['elapsed_time_diff_mean'] = np.mean(elapsed_time_diff_all)\n",
    "    res['elapsed_time_diff_std'] = np.std(elapsed_time_diff_all)\n",
    "    res['elapsed_time_diff_max'] = np.max(elapsed_time_diff_all)\n",
    "    res['elapsed_time_diff_min'] = np.min(elapsed_time_diff_all)\n",
    "    res['elapsed_time_diff_positive'] = len(elapsed_time_diff_all[elapsed_time_diff_all>0])\n",
    "    \n",
    "    for col in event_features:\n",
    "        elapsed_time_diff_event = elapsed_time_diff_all[event_sequence==col]\n",
    "        elapsed_time_diff_event = elapsed_time_diff_event if len(elapsed_time_diff_event) > 0 else [0]\n",
    "        res[f'elapsed_time_diff_{col}_mean'] = np.mean(elapsed_time_diff_event)\n",
    "        res[f'elapsed_time_diff_{col}_max'] = np.max(elapsed_time_diff_event)\n",
    "        res[f'elapsed_time_diff_{col}_min'] = np.min(elapsed_time_diff_event)\n",
    "        res[f'elapsed_time_diff_{col}_std'] = np.std(elapsed_time_diff_event)\n",
    "    fqid_sequence = g['fqid'].values\n",
    "    for col in fqid_lists:\n",
    "        elapsed_time_diff_fqid = elapsed_time_diff_all[fqid_sequence==col]\n",
    "        elapsed_time_diff_fqid = elapsed_time_diff_fqid if len(elapsed_time_diff_fqid) > 0 else [0]\n",
    "        res[f'elapsed_time_diff_{col}_mean'] = np.mean(elapsed_time_diff_fqid)\n",
    "        res[f'elapsed_time_diff_{col}_max'] = np.max(elapsed_time_diff_fqid)\n",
    "        res[f'elapsed_time_diff_{col}_min'] = np.min(elapsed_time_diff_fqid)\n",
    "        res[f'elapsed_time_diff_{col}_std'] = np.std(elapsed_time_diff_fqid)\n",
    "    \n",
    "    text_sequence = g['text_fqid'].values\n",
    "    for col in text_lists:\n",
    "        elapsed_time_diff_text = elapsed_time_diff_all[text_sequence==col]\n",
    "        elapsed_time_diff_text = elapsed_time_diff_text if len(elapsed_time_diff_text) > 0 else [0]\n",
    "        res[f'elapsed_time_diff_{col}_mean'] = np.mean(elapsed_time_diff_text)\n",
    "        res[f'elapsed_time_diff_{col}_max'] = np.max(elapsed_time_diff_text)\n",
    "        res[f'elapsed_time_diff_{col}_min'] = np.min(elapsed_time_diff_text)\n",
    "        res[f'elapsed_time_diff_{col}_std'] = np.std(elapsed_time_diff_text)\n",
    "    return pd.Series(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0932b3-2faa-4c75-821a-ac4fad745282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, meta):\n",
    "    df['main_room'] = df['room_fqid'].str.split('.').str[1]\n",
    "    df['room_event'] =  df['event_name']+'_' + df['main_room']\n",
    "    X = df.groupby(['session','level_group']).apply(groupby_apply).reset_index()\n",
    "    X = meta.merge(X,how='left', on=['session','level_group'])\n",
    "    X['question'] = X['question'].astype('category')\n",
    "    X['level_group'] = X['level_group'].astype('category')\n",
    "    for i in range(1,19):\n",
    "        X[f'q{i}'] = X['question'] == i\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df42cabf-bbef-48e5-a02a-cec6c142627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Config.TRAIN_PATH, usecols=lambda x: x not in ['fullscreen','hq','music'])\n",
    "train_labels = pd.read_csv(Config.TRAIN_LABELS)\n",
    "train_df.rename(columns={'session_id':'session'},inplace=True)\n",
    "train_labels['question'] = train_labels['session_id'].str.split('q').str[-1].astype('int')\n",
    "train_labels['session'] = train_labels['session_id'].str.split('_').str[0].astype('int64')\n",
    "train_labels['level_group'] = train_labels['question'].apply(lambda x: q2l(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6d5e91-41f6-4479-a269-8f5637b719a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['elapsed_time_diff'] = train_df.groupby(['session','level'])['elapsed_time'].diff()\n",
    "train_df['elapsed_time_diff'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b8d1a5-5e5d-4302-ad1e-03e7ca018121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_feature(train):\n",
    "    train[\"year\"] = train[\"session_id\"].apply(lambda x: int(str(x)[:2])).astype(np.uint8)\n",
    "    train[\"month\"] = train[\"session_id\"].apply(lambda x: int(str(x)[2:4])+1).astype(np.uint8)\n",
    "    train[\"day\"] = train[\"session_id\"].apply(lambda x: int(str(x)[4:6])).astype(np.uint8)\n",
    "    train[\"hour\"] = train[\"session_id\"].apply(lambda x: int(str(x)[6:8])).astype(np.uint8)\n",
    "    train[\"minute\"] = train[\"session_id\"].apply(lambda x: int(str(x)[8:10])).astype(np.uint8)\n",
    "    train[\"second\"] = train[\"session_id\"].apply(lambda x: int(str(x)[10:12])).astype(np.uint8)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409a6ed-e67d-425a-8a0e-fd72a2b2eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = feature_engineering(train_df, train_labels)\n",
    "X = time_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715300a-c71c-4b6a-8a46-50f30706def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62e193-dadc-4f8a-9eeb-29dc22426916",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = X.columns[5:]\n",
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d84344a-1bba-46a0-a8a6-9f41820cfbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "oof = np.zeros(X.shape[0])\n",
    "models = {}\n",
    "\n",
    "# COMPUTE CV SCORE WITH 5 GROUP K FOLD\n",
    "for i, (train_index, valid_index) in enumerate(gkf.split(X, groups=X['session'])):\n",
    "    print('#'*25)\n",
    "    print('### Fold',i+1)\n",
    "    print('#'*25)\n",
    "\n",
    "    xgb_params = {\n",
    "        'objective' : 'binary:logistic',\n",
    "        'eval_metric':'logloss',\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 5,\n",
    "        'n_estimators': 3000,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'subsample':0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'seed':42,\n",
    "        'use_label_encoder' : False}\n",
    "\n",
    "    X_train = X.iloc[train_index][FEATURES]\n",
    "    X_valid = X.iloc[valid_index][FEATURES]\n",
    "    y_train = X.iloc[train_index]['correct'].values\n",
    "    y_valid = X.iloc[valid_index]['correct'].values\n",
    "        # TRAIN MODEL\n",
    "    clf =  XGBClassifier(**xgb_params)\n",
    "    clf.fit(X_train.astype('float32'), y_train,\n",
    "            eval_set=[(X_train.astype('float32'), y_train), (X_valid.astype('float32'),y_valid)],\n",
    "            verbose=100)\n",
    "    print(f'({clf.best_ntree_limit}), ',end='')\n",
    "\n",
    "        # SAVE MODEL, PREDICT VALID OOF\n",
    "    models[i] = clf\n",
    "    oof[valid_index] = clf.predict_proba(X_valid)[:,1]\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4fa07-e00b-4b3e-a75b-3f6488a441ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    fi_df = fi_df.tail(50)\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(20,10))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "feat_imp = {}\n",
    "for k, v in models.items():\n",
    "    for x, y in zip(v.feature_importances_, v.feature_names_in_):\n",
    "        if y not in feat_imp:\n",
    "            feat_imp[y] = x\n",
    "        else:\n",
    "            feat_imp[y]+=x\n",
    "plot_feature_importance(list(feat_imp.values()),list(feat_imp.keys()),'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8789190-a549-478a-946e-2e23bbe59dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []; thresholds = []\n",
    "best_score = 0; best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0.4,0.9,0.01):\n",
    "    print(f'{threshold:.02f}, ',end='')\n",
    "    preds = (oof>threshold).astype('int')\n",
    "    m = f1_score(X['correct'], preds, average='macro')\n",
    "    scores.append(m)\n",
    "    thresholds.append(threshold)\n",
    "    if m>best_score:\n",
    "        best_score = m\n",
    "        best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765dcdf-5fa2-40d1-a431-8b69e7a2a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PLOT THRESHOLD VS. F1_SCORE\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(thresholds,scores,'-o',color='blue')\n",
    "plt.scatter([best_threshold], [best_score], color='blue', s=300, alpha=1)\n",
    "plt.xlabel('Threshold',size=14)\n",
    "plt.ylabel('Validation F1 Score',size=14)\n",
    "plt.title(f'Threshold vs. F1_Score with Best F1_Score = {best_score:.4f} at Best Threshold = {best_threshold:.3}',size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7c23a-8a96-40ea-b2e3-c87a9b8b1e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
